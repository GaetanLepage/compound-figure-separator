************* Module compfigsep.label_recognition.label_recog_retinanet
compfigsep/label_recognition/label_recog_retinanet.py:334:2: W0511: TODO remove (fixme)
compfigsep/label_recognition/label_recog_retinanet.py:479:2: W0511: TODO import from detectron2 directly as we should not need to change the head. (fixme)
compfigsep/label_recognition/label_recog_retinanet.py:31:0: E0611: No name 'LongTensor' in module 'torch' (no-name-in-module)
compfigsep/label_recognition/label_recog_retinanet.py:86:0: W0223: Method '_forward_unimplemented' is abstract in class 'Module' but is not overridden (abstract-method)
compfigsep/label_recognition/label_recog_retinanet.py:86:0: R0902: Too many instance attributes (18/7) (too-many-instance-attributes)
compfigsep/label_recognition/label_recog_retinanet.py:153:4: R0914: Too many local variables (19/15) (too-many-locals)
compfigsep/label_recognition/label_recog_retinanet.py:217:4: R0913: Too many arguments (6/5) (too-many-arguments)
compfigsep/label_recognition/label_recog_retinanet.py:217:4: R0914: Too many local variables (17/15) (too-many-locals)
compfigsep/label_recognition/label_recog_retinanet.py:260:40: E0602: Undefined variable 'F' (undefined-variable)
compfigsep/label_recognition/label_recog_retinanet.py:378:4: R0914: Too many local variables (20/15) (too-many-locals)
compfigsep/label_recognition/label_recog_retinanet.py:480:0: W0223: Method '_forward_unimplemented' is abstract in class 'Module' but is not overridden (abstract-method)
************* Module compfigsep.label_recognition.load_datasets
compfigsep/label_recognition/load_datasets.py:45:2: W0511: TODO warn the user in this case (fixme)
compfigsep/label_recognition/load_datasets.py:56:2: W0511: TODO warn the user in this case (fixme)
************* Module compfigsep.label_recognition.post_processing
compfigsep/label_recognition/post_processing.py:38:0: C0301: Line too long (134/100) (line-too-long)
compfigsep/label_recognition/post_processing.py:30:18: W0613: Unused argument 'figure_generator' (unused-argument)
compfigsep/label_recognition/post_processing.py:27:0: W0611: Unused Figure imported from utils.figure (unused-import)
************* Module compfigsep.label_recognition.label_filtering
compfigsep/label_recognition/label_filtering.py:48:2: W0511: TODO (fixme)
compfigsep/label_recognition/label_filtering.py:179:2: W0511: TODO (fixme)
compfigsep/label_recognition/label_filtering.py:119:25: W0613: Unused argument 'label_from' (unused-argument)
compfigsep/label_recognition/label_filtering.py:120:25: W0613: Unused argument 'label_to' (unused-argument)
************* Module compfigsep.label_recognition.train_net
compfigsep/label_recognition/train_net.py:98:45: E1123: Unexpected keyword argument 'cfg' in constructor call (unexpected-keyword-arg)
compfigsep/label_recognition/train_net.py:98:45: E1125: Missing mandatory keyword argument 'augmentations' in constructor call (missing-kwoa)
compfigsep/label_recognition/train_net.py:98:45: E1125: Missing mandatory keyword argument 'image_format' in constructor call (missing-kwoa)
************* Module compfigsep.label_recognition.evaluate
compfigsep/label_recognition/evaluate.py:52:2: W0511: TODO remove (fixme)
compfigsep/label_recognition/evaluate.py:67:2: W0511: TODO remove (fixme)
compfigsep/label_recognition/evaluate.py:81:2: W0511: TODO remove (fixme)
************* Module compfigsep.caption_splitting.subcaptions_extraction
compfigsep/caption_splitting/subcaptions_extraction.py:128:2: W0511: TODO : should remove or not ? (fixme)
compfigsep/caption_splitting/subcaptions_extraction.py:210:2: W0511: TODO unclear how positions are sorted (fixme)
compfigsep/caption_splitting/subcaptions_extraction.py:443:2: W0511: TODO rephrase: (fixme)
compfigsep/caption_splitting/subcaptions_extraction.py:33:0: E0401: Unable to import 'nltk' (import-error)
compfigsep/caption_splitting/subcaptions_extraction.py:407:0: R0913: Too many arguments (6/5) (too-many-arguments)
compfigsep/caption_splitting/subcaptions_extraction.py:486:0: R0913: Too many arguments (7/5) (too-many-arguments)
compfigsep/caption_splitting/subcaptions_extraction.py:486:0: R0912: Too many branches (13/12) (too-many-branches)
compfigsep/caption_splitting/subcaptions_extraction.py:618:0: R0913: Too many arguments (7/5) (too-many-arguments)
compfigsep/caption_splitting/subcaptions_extraction.py:618:0: R0914: Too many local variables (19/15) (too-many-locals)
compfigsep/caption_splitting/subcaptions_extraction.py:618:0: R0912: Too many branches (20/12) (too-many-branches)
************* Module compfigsep.caption_splitting.replaceutf8
compfigsep/caption_splitting/replaceutf8.py:27:15: W0109: Duplicate key '⁻' in dictionary (duplicate-key)
compfigsep/caption_splitting/replaceutf8.py:27:15: W0109: Duplicate key '₋' in dictionary (duplicate-key)
compfigsep/caption_splitting/replaceutf8.py:27:15: W0109: Duplicate key 'Ő' in dictionary (duplicate-key)
compfigsep/caption_splitting/replaceutf8.py:27:15: W0109: Duplicate key 'Ɖ' in dictionary (duplicate-key)
compfigsep/caption_splitting/replaceutf8.py:27:15: W0109: Duplicate key 'Ɛ' in dictionary (duplicate-key)
compfigsep/caption_splitting/replaceutf8.py:27:15: W0109: Duplicate key '\u200b' in dictionary (duplicate-key)
compfigsep/caption_splitting/replaceutf8.py:27:15: W0109: Duplicate key '\u200e' in dictionary (duplicate-key)
************* Module compfigsep.caption_splitting.label_filtering
compfigsep/caption_splitting/label_filtering.py:31:0: W0102: Dangerous default value [] as argument (dangerous-default-value)
************* Module compfigsep.caption_splitting.bin.test
compfigsep/caption_splitting/bin/test.py:120:0: C0301: Line too long (107/100) (line-too-long)
compfigsep/caption_splitting/bin/test.py:125:0: C0301: Line too long (106/100) (line-too-long)
compfigsep/caption_splitting/bin/test.py:128:0: C0301: Line too long (107/100) (line-too-long)
compfigsep/caption_splitting/bin/test.py:118:2: W0511: TODO label 'B' is not detected in this example. (fixme)
************* Module compfigsep.panel_segmentation.dataset_mapper
compfigsep/panel_segmentation/dataset_mapper.py:106:2: W0511: TODO remove (fixme)
compfigsep/panel_segmentation/dataset_mapper.py:158:2: W0511: TODO simplify this (fixme)
compfigsep/panel_segmentation/dataset_mapper.py:232:2: W0511: TODO check if we have to adapt this for handling panel_boxes and label_boxes (fixme)
compfigsep/panel_segmentation/dataset_mapper.py:118:24: E1102: torch.tensor is not callable (not-callable)
compfigsep/panel_segmentation/dataset_mapper.py:136:24: E1102: torch.tensor is not callable (not-callable)
compfigsep/panel_segmentation/dataset_mapper.py:160:32: E1123: Unexpected keyword argument 'transform_gens' in function call (unexpected-keyword-arg)
compfigsep/panel_segmentation/dataset_mapper.py:160:32: E1123: Unexpected keyword argument 'img' in function call (unexpected-keyword-arg)
compfigsep/panel_segmentation/dataset_mapper.py:160:32: E1120: No value for argument 'augmentations' in function call (no-value-for-parameter)
compfigsep/panel_segmentation/dataset_mapper.py:160:32: E1120: No value for argument 'inputs' in function call (no-value-for-parameter)
compfigsep/panel_segmentation/dataset_mapper.py:45:0: R0903: Too few public methods (1/2) (too-few-public-methods)
************* Module compfigsep.panel_segmentation.load_datasets
compfigsep/panel_segmentation/load_datasets.py:42:2: W0511: TODO warn the user in this case (fixme)
compfigsep/panel_segmentation/load_datasets.py:70:2: W0511: TODO remove if it is indeed useless (fixme)
compfigsep/panel_segmentation/load_datasets.py:48:8: W0612: Unused variable 'image_directory_path' (unused-variable)
compfigsep/panel_segmentation/load_datasets.py:31:0: W0611: Unused LABEL_CLASS_MAPPING imported from utils.figure.label (unused-import)
************* Module compfigsep.panel_segmentation.panel_seg_retinanet
compfigsep/panel_segmentation/panel_seg_retinanet.py:189:2: W0511: TODO maybe have to duplicate those as well (fixme)
compfigsep/panel_segmentation/panel_seg_retinanet.py:338:2: W0511: TODO check that this work with two sets of boxes (fixme)
compfigsep/panel_segmentation/panel_seg_retinanet.py:30:0: E0611: No name 'LongTensor' in module 'torch' (no-name-in-module)
compfigsep/panel_segmentation/panel_seg_retinanet.py:96:0: W0223: Method '_forward_unimplemented' is abstract in class 'Module' but is not overridden (abstract-method)
compfigsep/panel_segmentation/panel_seg_retinanet.py:96:0: R0902: Too many instance attributes (20/7) (too-many-instance-attributes)
compfigsep/panel_segmentation/panel_seg_retinanet.py:222:4: R0914: Too many local variables (37/15) (too-many-locals)
compfigsep/panel_segmentation/panel_seg_retinanet.py:369:4: R0913: Too many arguments (7/5) (too-many-arguments)
compfigsep/panel_segmentation/panel_seg_retinanet.py:369:4: R0914: Too many local variables (18/15) (too-many-locals)
compfigsep/panel_segmentation/panel_seg_retinanet.py:504:4: R0913: Too many arguments (8/5) (too-many-arguments)
compfigsep/panel_segmentation/panel_seg_retinanet.py:504:4: R0914: Too many local variables (18/15) (too-many-locals)
compfigsep/panel_segmentation/panel_seg_retinanet.py:580:4: R0914: Too many local variables (22/15) (too-many-locals)
compfigsep/panel_segmentation/panel_seg_retinanet.py:657:4: R0913: Too many arguments (6/5) (too-many-arguments)
compfigsep/panel_segmentation/panel_seg_retinanet.py:720:0: W0223: Method '_forward_unimplemented' is abstract in class 'Module' but is not overridden (abstract-method)
************* Module compfigsep.panel_segmentation.train_net
compfigsep/panel_segmentation/train_net.py:137:2: W0511: TODO remove as it can't work (fixme)
compfigsep/panel_segmentation/train_net.py:179:10: W0621: Redefining name 'parsed_args' from outer scope (line 268) (redefined-outer-name)
compfigsep/panel_segmentation/train_net.py:30:0: W0611: Unused import os (unused-import)
************* Module compfigsep.panel_segmentation.evaluator
compfigsep/panel_segmentation/evaluator.py:62:4: R0914: Too many local variables (19/15) (too-many-locals)
************* Module compfigsep.panel_segmentation.evaluate
compfigsep/panel_segmentation/evaluate.py:57:2: W0511: TODO: this choice might not be smart (fixme)
compfigsep/panel_segmentation/evaluate.py:134:2: W0511: TODO : clean this function (fixme)
compfigsep/panel_segmentation/evaluate.py:152:2: W0511: TODO manage the case where no labels have been detected (fixme)
compfigsep/panel_segmentation/evaluate.py:194:2: W0511: TODO remove (fixme)
************* Module compfigsep.data.export
compfigsep/data/export.py:240:2: W0511: TODO: later, we would like to handle >1 length labels (fixme)
compfigsep/data/export.py:174:4: C0415: Import outside toplevel (detectron2.structures.BoxMode) (import-outside-toplevel)
************* Module compfigsep.data.figure_generators.global_csv_figure_generator
compfigsep/data/figure_generators/global_csv_figure_generator.py:36:0: R0903: Too few public methods (1/2) (too-few-public-methods)
************* Module compfigsep.data.figure_generators.json_figure_generator
compfigsep/data/figure_generators/json_figure_generator.py:52:0: R0914: Too many local variables (22/15) (too-many-locals)
************* Module compfigsep.data.figure_generators.prostate_caption_figure_generator
compfigsep/data/figure_generators/prostate_caption_figure_generator.py:37:0: R0903: Too few public methods (1/2) (too-few-public-methods)
************* Module compfigsep.data.figure_generators.individual_csv_figure_generator
compfigsep/data/figure_generators/individual_csv_figure_generator.py:62:2: W0511: TODO implement the call method for the IndividualCsvFigureGenerator. (fixme)
compfigsep/data/figure_generators/individual_csv_figure_generator.py:32:0: R0903: Too few public methods (1/2) (too-few-public-methods)
************* Module compfigsep.data.bin.export_iphotodraw_figures_to_csv
compfigsep/data/bin/export_iphotodraw_figures_to_csv.py:36:0: C0413: Import "from compfigsep.data.figure_generators import IphotodrawXmlFigureGenerator" should be placed at the top of the module (wrong-import-position)
compfigsep/data/bin/export_iphotodraw_figures_to_csv.py:37:0: C0413: Import "from compfigsep.data.export import export_figures_to_csv" should be placed at the top of the module (wrong-import-position)
************* Module compfigsep.data.bin.preview_imageclef_data_set
compfigsep/data/bin/preview_imageclef_data_set.py:37:0: C0413: Import "from compfigsep.data.figure_generators import ImageClefXmlFigureGenerator" should be placed at the top of the module (wrong-import-position)
compfigsep/data/bin/preview_imageclef_data_set.py:38:0: C0413: Import "from compfigsep.data.figure_viewer import add_viewer_args, view_data_set" should be placed at the top of the module (wrong-import-position)
************* Module compfigsep.data.bin.preview_json_data_set
compfigsep/data/bin/preview_json_data_set.py:53:2: W0511: TODO check default path (fixme)
compfigsep/data/bin/preview_json_data_set.py:37:0: C0413: Import "from compfigsep.data.figure_generators import JsonFigureGenerator" should be placed at the top of the module (wrong-import-position)
compfigsep/data/bin/preview_json_data_set.py:38:0: C0413: Import "from compfigsep.data.figure_viewer import add_viewer_args, view_data_set" should be placed at the top of the module (wrong-import-position)
compfigsep/data/bin/preview_json_data_set.py:30:0: W0611: Unused import os (unused-import)
************* Module compfigsep.data.bin.download_captions
compfigsep/data/bin/download_captions.py:71:0: R0914: Too many local variables (20/15) (too-many-locals)
compfigsep/data/bin/download_captions.py:112:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
compfigsep/data/bin/download_captions.py:162:16: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
compfigsep/data/bin/download_captions.py:166:12: W1203: Use lazy % formatting in logging functions (logging-fstring-interpolation)
************* Module compfigsep.data.bin.export_imageclef_figures_to_csv
compfigsep/data/bin/export_imageclef_figures_to_csv.py:36:0: C0413: Import "from compfigsep.data.figure_generators import ImageClefXmlFigureGenerator" should be placed at the top of the module (wrong-import-position)
compfigsep/data/bin/export_imageclef_figures_to_csv.py:37:0: C0413: Import "from compfigsep.data.export import export_figures_to_csv" should be placed at the top of the module (wrong-import-position)
************* Module compfigsep.data.bin.export_imageclef_figures_to_tfrecord
compfigsep/data/bin/export_imageclef_figures_to_tfrecord.py:37:0: C0413: Import "from compfigsep.data.figure_generators import ImageClefXmlFigureGenerator" should be placed at the top of the module (wrong-import-position)
compfigsep/data/bin/export_imageclef_figures_to_tfrecord.py:38:0: E0611: No name 'export_figures_to_tf_record' in module 'compfigsep.data.export' (no-name-in-module)
compfigsep/data/bin/export_imageclef_figures_to_tfrecord.py:38:0: C0413: Import "from compfigsep.data.export import export_figures_to_tf_record" should be placed at the top of the module (wrong-import-position)
************* Module compfigsep.data.bin.preview_global_csv_data_set
compfigsep/data/bin/preview_global_csv_data_set.py:36:0: C0413: Import "from compfigsep.data.figure_generators import GlobalCsvFigureGenerator" should be placed at the top of the module (wrong-import-position)
compfigsep/data/bin/preview_global_csv_data_set.py:37:0: C0413: Import "from compfigsep.data.figure_viewer import add_viewer_args, view_data_set" should be placed at the top of the module (wrong-import-position)
compfigsep/data/bin/preview_global_csv_data_set.py:76:23: E0110: Abstract class 'GlobalCsvFigureGenerator' with abstract methods instantiated (abstract-class-instantiated)
************* Module compfigsep.utils.logger
compfigsep/utils/logger.py:25:0: C0305: Trailing newlines (trailing-newlines)
************* Module compfigsep.utils.detectron_utils.loss_eval_hook
compfigsep/utils/detectron_utils/loss_eval_hook.py:122:8: E1101: Instance of 'LossEvalHook' has no 'trainer' member (no-member)
compfigsep/utils/detectron_utils/loss_eval_hook.py:154:25: E1101: Instance of 'LossEvalHook' has no 'trainer' member (no-member)
compfigsep/utils/detectron_utils/loss_eval_hook.py:155:38: E1101: Instance of 'LossEvalHook' has no 'trainer' member (no-member)
************* Module compfigsep.utils.detectron_utils.evaluator
compfigsep/utils/detectron_utils/evaluator.py:46:0: R0902: Too many instance attributes (9/7) (too-many-instance-attributes)
compfigsep/utils/detectron_utils/evaluator.py:64:4: R0913: Too many arguments (6/5) (too-many-arguments)
************* Module compfigsep.utils.figure.beam_search
compfigsep/utils/figure/beam_search.py:85:2: W0511: TODO remove (fixme)
compfigsep/utils/figure/beam_search.py:135:2: W0511: TODO remove (fixme)
compfigsep/utils/figure/beam_search.py:139:2: W0511: TODO remove (fixme)
compfigsep/utils/figure/beam_search.py:68:0: R0914: Too many local variables (21/15) (too-many-locals)
************* Module compfigsep.utils.figure.figure
compfigsep/utils/figure/figure.py:1:0: C0302: Too many lines in module (1185/1000) (too-many-lines)
compfigsep/utils/figure/figure.py:362:2: W0511: TODO check what to do in this case (fixme)
compfigsep/utils/figure/figure.py:749:2: W0511: TODO laverage the 'single-character label' restriction. (fixme)
compfigsep/utils/figure/figure.py:811:2: W0511: TODO laverage the 'single-character label' restriction. (fixme)
compfigsep/utils/figure/figure.py:49:0: R0902: Too many instance attributes (17/7) (too-many-instance-attributes)
compfigsep/utils/figure/figure.py:185:14: I1101: Module 'cv2.cv2' has no 'imread' member, but source is unavailable. Consider adding this module to extension-pkg-whitelist if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
compfigsep/utils/figure/figure.py:198:4: R0914: Too many local variables (17/15) (too-many-locals)
compfigsep/utils/figure/figure.py:274:4: R0914: Too many local variables (16/15) (too-many-locals)
compfigsep/utils/figure/figure.py:274:4: R0915: Too many statements (99/50) (too-many-statements)
compfigsep/utils/figure/figure.py:633:4: R0914: Too many local variables (17/15) (too-many-locals)
compfigsep/utils/figure/figure.py:853:32: E1101: Instance of 'Figure' has no 'detected_captions' member (no-member)
compfigsep/utils/figure/figure.py:865:22: E0602: Undefined variable 'text' (undefined-variable)
compfigsep/utils/figure/figure.py:870:51: E0602: Undefined variable 'gt_label_index' (undefined-variable)
compfigsep/utils/figure/figure.py:874:25: E0602: Undefined variable 'iou_threshold' (undefined-variable)
compfigsep/utils/figure/figure.py:875:28: E0602: Undefined variable 'picked_gt_labels_indices' (undefined-variable)
compfigsep/utils/figure/figure.py:876:16: E0602: Undefined variable 'picked_gt_labels_indices' (undefined-variable)
compfigsep/utils/figure/figure.py:877:16: E0602: Undefined variable 'detected_label' (undefined-variable)
compfigsep/utils/figure/figure.py:881:16: E0602: Undefined variable 'detected_label' (undefined-variable)
compfigsep/utils/figure/figure.py:850:8: W0612: Unused variable 'picked_gt_captions_indices' (unused-variable)
compfigsep/utils/figure/figure.py:855:12: W0612: Unused variable 'best_matching_gt_caption_index' (unused-variable)
compfigsep/utils/figure/figure.py:857:16: W0612: Unused variable 'gt_caption_index' (unused-variable)
compfigsep/utils/figure/figure.py:888:4: R0912: Too many branches (22/12) (too-many-branches)
compfigsep/utils/figure/figure.py:1035:8: I1101: Module 'cv2.cv2' has no 'imshow' member, but source is unavailable. Consider adding this module to extension-pkg-whitelist if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
compfigsep/utils/figure/figure.py:1036:8: I1101: Module 'cv2.cv2' has no 'waitKey' member, but source is unavailable. Consider adding this module to extension-pkg-whitelist if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
compfigsep/utils/figure/figure.py:1037:8: I1101: Module 'cv2.cv2' has no 'destroyAllWindows' member, but source is unavailable. Consider adding this module to extension-pkg-whitelist if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
compfigsep/utils/figure/figure.py:1074:15: I1101: Module 'cv2.cv2' has no 'imwrite' member, but source is unavailable. Consider adding this module to extension-pkg-whitelist if you want to perform analysis based on run-time introspection of living objects. (c-extension-no-member)
************* Module compfigsep.utils.figure.sub_figure
compfigsep/utils/figure/sub_figure.py:211:4: W0221: Parameters differ from overridden 'from_dict' method (arguments-differ)
************* Module compfigsep.utils.figure.panel
compfigsep/utils/figure/panel.py:102:12: E1101: Module 'cv2' has no 'rectangle' member (no-member)
************* Module compfigsep.utils.figure.label.__init__
compfigsep/utils/figure/label/__init__.py:32:0: C0305: Trailing newlines (trailing-newlines)
************* Module compfigsep.utils.figure.label.label
compfigsep/utils/figure/label/label.py:115:12: E1101: Module 'cv2' has no 'rectangle' member (no-member)
compfigsep/utils/figure/label/label.py:123:16: E1101: Module 'cv2' has no 'putText' member (no-member)
compfigsep/utils/figure/label/label.py:127:37: E1101: Module 'cv2' has no 'FONT_HERSHEY_SIMPLEX' member (no-member)
compfigsep/utils/figure/label/label.py:241:4: W0235: Useless super delegation in method 'draw' (useless-super-delegation)
************* Module compfigsep.utils.figure.label.labels_structure
compfigsep/utils/figure/label/labels_structure.py:128:2: W0511: TODO maybe put in histogram... (fixme)
compfigsep/utils/figure/label/labels_structure.py:151:2: W0511: TODO remove (fixme)
compfigsep/utils/figure/label/labels_structure.py:162:2: W0511: TODO Add comments to explain this ultra smart strategy (fixme)
************* Module compfigsep.panel_splitting.load_datasets
compfigsep/panel_splitting/load_datasets.py:58:2: W0511: TODO warn the user in this case (fixme)
compfigsep/panel_splitting/load_datasets.py:75:2: W0511: TODO warn the user in this case (fixme)
compfigsep/panel_splitting/load_datasets.py:82:2: W0511: TODO warn the user in this case (fixme)
************* Module compfigsep.panel_splitting.train_net
compfigsep/panel_splitting/train_net.py:90:30: E1123: Unexpected keyword argument 'cfg' in constructor call (unexpected-keyword-arg)
compfigsep/panel_splitting/train_net.py:90:30: E1125: Missing mandatory keyword argument 'augmentations' in constructor call (missing-kwoa)
compfigsep/panel_splitting/train_net.py:90:30: E1125: Missing mandatory keyword argument 'image_format' in constructor call (missing-kwoa)
compfigsep/panel_splitting/train_net.py:106:10: W0621: Redefining name 'parsed_args' from outer scope (line 188) (redefined-outer-name)
compfigsep/panel_splitting/train_net.py:148:9: W0621: Redefining name 'parsed_args' from outer scope (line 188) (redefined-outer-name)
************* Module compfigsep.panel_splitting.evaluator
compfigsep/panel_splitting/evaluator.py:115:2: W0511: TODO do some post processing here maybe (fixme)
compfigsep/panel_splitting/evaluator.py:72:12: W0622: Redefining built-in 'input' (redefined-builtin)
compfigsep/panel_splitting/evaluator.py:29:0: W0611: Unused FigureGenerator imported from data.figure_generators (unused-import)
compfigsep/panel_splitting/evaluator.py:29:0: W0611: Unused StackedFigureGenerator imported from data.figure_generators (unused-import)
************* Module compfigsep.panel_splitting.predict
compfigsep/panel_splitting/predict.py:153:20: E0602: Undefined variable 'SubFigure' (undefined-variable)
compfigsep/panel_splitting/predict.py:30:0: W0611: Unused Panel imported from utils.figure (unused-import)
************* Module compfigsep.panel_splitting.evaluate
compfigsep/panel_splitting/evaluate.py:1:0: R0401: Cyclic import (compfigsep.utils.figure -> compfigsep.utils.figure.beam_search -> compfigsep.utils.figure.sub_figure) (cyclic-import)
compfigsep/panel_splitting/evaluate.py:1:0: R0401: Cyclic import (compfigsep.utils.figure -> compfigsep.utils.figure.sub_figure) (cyclic-import)
compfigsep/panel_splitting/evaluate.py:1:0: R0401: Cyclic import (compfigsep.utils.figure -> compfigsep.utils.figure.figure -> compfigsep.utils.figure.beam_search -> compfigsep.utils.figure.sub_figure) (cyclic-import)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.label_recog_retinanet:499
==compfigsep.panel_segmentation.panel_seg_retinanet:746
        num_anchors_int: int = num_anchors[0]

        cls_subnet: List[nn.Module] = []
        bbox_subnet: List[nn.Module] = []
        for _ in range(num_convs):
            cls_subnet.append(nn.Conv2d(in_channels,
                                        in_channels,
                                        kernel_size=3,
                                        stride=1,
                                        padding=1))
            cls_subnet.append(nn.ReLU())
            bbox_subnet.append(nn.Conv2d(in_channels,
                                         in_channels,
                                         kernel_size=3,
                                         stride=1,
                                         padding=1))
            bbox_subnet.append(nn.ReLU())

        self.cls_subnet = nn.Sequential(*cls_subnet)
        self.bbox_subnet = nn.Sequential(*bbox_subnet)
        self.cls_score = nn.Conv2d(in_channels,
                                   num_anchors_int
                                   * num_classes,
                                   kernel_size=3,
                                   stride=1,
                                   padding=1)

        self.bbox_pred = nn.Conv2d(in_channels,
                                   num_anchors_int * 4,
                                   kernel_size=3,
                                   stride=1,
                                   padding=1)

        # Initialization
        for modules in [self.cls_subnet,
                        self.bbox_subnet,
                        self.cls_score,
                        self.bbox_pred]:

            for layer in modules.modules():
                if isinstance(layer, nn.Conv2d):
                    torch.nn.init.normal_(tensor=layer.weight,
                                          mean=0,
                                          std=0.01)
                    torch.nn.init.constant_(tensor=layer.bias,
                                            val=0)

        # Use prior in model initialization to improve stability
        bias_value: float = -math.log((1 - prior_prob) / prior_prob)
        torch.nn.init.constant_(self.cls_score.bias,
                                bias_value)

 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.utils.figure.label.label:98
==compfigsep.utils.figure.panel:85
        return output_dict


    def draw(self,
             image: np.ndarray,
             color: Color = DEFAULT_GT_COLOR) -> None:
        """
        Draw the label bounding box and text on the image.
        The image is affected by side-effect.

        Args:
            image (np.ndarray): Image to override with annotations.
            color (Color):      Color to draw the element with (in RGB format).
        """
        # Draw label box
        if self.box is not None:
            cv2.rectangle(img=image,
                          pt1=(self.box[0], self.box[1]),
                          pt2=(self.box[2], self.box[3]),
                          color=color,
                          thickness=2)

            # Draw label text (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 3 files
==compfigsep.data.bin.export_imageclef_figures_to_csv:77
==compfigsep.data.bin.export_imageclef_figures_to_tfrecord:70
==compfigsep.data.bin.preview_imageclef_data_set:64
    return parser.parse_args(args)


def main(args: List[str] = None):
    """
    Load figures from ImageCLEF xml annotation files and export them to csv.

    Args:
        args (List[str]):   Arguments from the command line.
    """

    # Parse arguments.
    if args is None:
        args = sys.argv[1:]
    args = parse_args(args)

    # Create the figure generator handling xml annotation files
    figure_generator = ImageClefXmlFigureGenerator(
        xml_annotation_file_path=args.annotation_xml,
        image_directory_path=args.image_directory_path)

    # Export figures to csv (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.train_net:129
==compfigsep.panel_segmentation.train_net:171
        model.to(torch.device(cfg.MODEL.DEVICE))
        logger = setup_logger(name=__name__,
                              distributed_rank=comm.get_rank())
        logger.info("Model:\n%s", model)
        return model


def setup(parsed_args: Namespace) -> CfgNode:
    """
    Create configs and perform basic setups.

    Args:
        args (List[str]): Arguments from the command line.

    Retuns:
        cfg (CfgNode): A config node filled with necessary options.
    """
    cfg = get_cfg()

    # Add some config options to handle validation
    add_validation_config(cfg)
 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 3 files
==compfigsep.data.bin.preview_imageclef_data_set:60
==compfigsep.data.bin.preview_json_data_set:56
==compfigsep.data.bin.preview_panelseg_data_set:59
                        type=str)

    add_viewer_args(parser)

    return parser.parse_args(args)


def main(args: List[str] = None):
    """
    Launch previsualization of Zou's data set.

    Args:
        args (List[str]):   Arguments from the command line.
    """

    # Parse arguments.
    if args is None:
        args = sys.argv[1:]
    args = parse_args(args)

    # Create the figure generator handling iPhotoDraw annotation files. (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.bin.export_imageclef_figures_to_csv:73
==compfigsep.data.bin.export_iphotodraw_figures_to_csv:73
                             " annotation files.",
                        default="data/imageCLEF/test/test.csv",
                        type=str)

    return parser.parse_args(args)


def main(args: List[str] = None):
    """
    Load figures from ImageCLEF xml annotation files and export them to csv.

    Args:
        args (List[str]):   Arguments from the command line.
    """

    # Parse arguments.
    if args is None:
        args = sys.argv[1:]
    args = parse_args(args)

    # Create the figure generator handling xml annotation files (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.bin.export_iphotodraw_figures_to_csv:77
==compfigsep.data.bin.preview_panelseg_data_set:63
    return parser.parse_args(args)


def main(args: List[str] = None):
    """
    Launch previsualization of Zou's data set.

    Args:
        args (List[str]):   Arguments from the command line.
    """

    # Parse arguments.
    if args is None:
        args = sys.argv[1:]
    args = parse_args(args)

    # Create the figure generator handling iPhotoDraw annotation files.
    figure_generator = IphotodrawXmlFigureGenerator(
        file_list_txt=args.file_list_txt,
        image_directory_path=args.image_directory_path)
 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.train_net:136
==compfigsep.panel_splitting.train_net:105
def setup(parsed_args: Namespace) -> CfgNode:
    """
    Create configs and perform basic setups.

    Args:
        args (List[str]): Arguments from the command line.

    Retuns:
        cfg (CfgNode): A config node filled with necessary options.
    """
    cfg = get_cfg()

    # Add some config options to handle validation
    add_validation_config(cfg)

    cfg.merge_from_file(parsed_args.config_file)
    cfg.merge_from_list(parsed_args.opts)
    cfg.freeze()
    default_setup(cfg, parsed_args) (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.bin.export_iphotodraw_figures_to_json:36
==compfigsep.data.bin.zou_eval_to_csv_captions:37
sys.path.append(".")

def parse_args(args: List[str]) -> Namespace:
    """
    Parse the arguments from the command line.

    Args:
        args (List[str]):   The arguments from the command line call.

    Returns:
        namespace (Namespace):  Populated namespace.
    """
    parser = ArgumentParser(description="Convert annotations from individual iPhotoDraw"\
                                        " xml annotation files. to a CSV annotations file.")

    add_iphotodraw_args(parser=parser)

    parser.add_argument('--output_filename', (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 4 files
==compfigsep.data.bin.preview_global_csv_data_set:54
==compfigsep.data.bin.preview_imageclef_data_set:60
==compfigsep.data.bin.preview_json_data_set:56
==compfigsep.data.bin.preview_panelseg_data_set:59
                        type=str)

    add_viewer_args(parser)

    return parser.parse_args(args)


def main(args: List[str] = None):
    """
    Launch previsualization of Zou's data set.

    Args:
        args (List[str]):   Arguments from the command line.
    """

    # Parse arguments.
    if args is None:
        args = sys.argv[1:] (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.bin.export_iphotodraw_figures_to_json:59
==compfigsep.data.bin.preview_global_csv_data_set:58
    return parser.parse_args(args)


def main(args: List[str] = None):
    """
    Launch previsualization of a csv data set.

    Args:
        args (List[str]):   Arguments from the command line.
    """

    # Parse arguments.
    if args is None:
        args = sys.argv[1:]
    parsed_args = parse_args(args)

    # Create the figure generator handling a csv annotation file. (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 6 files
==compfigsep.data.bin.export_imageclef_figures_to_csv:77
==compfigsep.data.bin.export_imageclef_figures_to_tfrecord:70
==compfigsep.data.bin.export_iphotodraw_figures_to_csv:77
==compfigsep.data.bin.preview_imageclef_data_set:64
==compfigsep.data.bin.preview_json_data_set:60
==compfigsep.data.bin.preview_panelseg_data_set:63
    return parser.parse_args(args)


def main(args: List[str] = None):
    """
    Launch previsualization of ImageCLEF data set.

    Args:
        args (List[str]):   Arguments from the command line.
    """

    # Parse arguments.
    if args is None:
        args = sys.argv[1:]
    args = parse_args(args)

    # Create the figure generator handling ImageCLEF xml annotation files. (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.bin.export_imageclef_figures_to_csv:77
==compfigsep.data.bin.preview_panelseg_data_set:63
    return parser.parse_args(args)


def main(args: List[str] = None):
    """
    Launch previsualization of Zou's data set.

    Args:
        args (List[str]):   Arguments from the command line.
    """

    # Parse arguments.
    if args is None:
        args = sys.argv[1:]
    args = parse_args(args)

    # Create the figure generator handling iPhotoDraw annotation files. (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.figure_generators.image_list_figure_generator:79
==compfigsep.data.figure_generators.prostate_caption_figure_generator:65
                if self.image_directory_path is not None:
                    image_file_path = os.path.join(self.image_directory_path, line[:-1])
                elif os.path.isfile(line):
                    image_file_path = line
                else:
                    image_file_path = os.path.join('data/', line)

                if not os.path.isfile(image_file_path):
                    logging.warning("File not found : %s", image_file_path)
                    continue

                figure = Figure(image_path=image_file_path,
                                index=image_counter)

                figure.load_image()

                yield figure (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.evaluator:82
==compfigsep.panel_splitting.evaluator:85
                prediction['box'] = box
                prediction['score'] = score
                predicted_panels.append(prediction)

            self._predictions[image_id] = predicted_panels


    def _predict(self, figure: Figure) -> None:
        """
        Write the predictions (stored in the `_predictions` attribute) in the appropriate
        attributes of the given figure object.
        The latter is modified by side effet.

        Args:
            figure (Figure):    A Figure object to augment with prediction data.
        """
 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.label_recog_retinanet:313
==compfigsep.panel_segmentation.panel_seg_retinanet:472
        anchors_boxes: Boxes = Boxes.cat(anchors)

        gt_classes: List[Tensor] = []
        matched_gt_boxes: List[Tensor] = []

        for gt_instance in gt_instances:
            match_quality_matrix: Tensor = pairwise_iou(gt_instance.gt_boxes,
                                                        anchors_boxes)
            matched_idxs, anchor_classes = self.anchor_matcher(match_quality_matrix)
            del match_quality_matrix

            if len(gt_instance) > 0:
                matched_gt_boxes_i: Tensor = gt_instance.gt_boxes.tensor[matched_idxs]

                gt_classes_i: Tensor = gt_instance.gt_classes[matched_idxs]

                # Anchors with class 0 are treated as background. (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 3 files
==compfigsep.data.bin.export_imageclef_figures_to_csv:75
==compfigsep.data.bin.export_iphotodraw_figures_to_csv:75
==compfigsep.data.bin.export_iphotodraw_figures_to_json:57
                        type=str)

    return parser.parse_args(args)


def main(args: List[str] = None):
    """
    Load figures from iPhotoDraw xml annotation files and export them to csv.

    Args:
        args (List[str]):   Arguments from the command line.
    """

    # Parse arguments.
    if args is None:
        args = sys.argv[1:] (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.panel_segmentation.train_net:196
==compfigsep.panel_splitting.train_net:120
    cfg.merge_from_file(parsed_args.config_file)
    cfg.merge_from_list(parsed_args.opts)
    cfg.freeze()
    default_setup(cfg, parsed_args)
    return cfg


def register_datasets(cfg: CfgNode):
    """
    Register the data sets needed for panel splitting in Detectron 2's registry.

    Args:
        cfg (CfgNode):  The config node filled with necessary options.
    """
    # Training
    for dataset_name in cfg.DATASETS.TRAIN: (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.panel_segmentation.train_net:145
==compfigsep.panel_splitting.train_net:90
                                                    is_train=True)
            data_loader = build_detection_test_loader(cfg=self.cfg,
                                                      dataset_name=self.cfg.DATASETS.VALIDATION,
                                                      mapper=data_set_mapper)

            loss_eval_hook = LossEvalHook(eval_period=self.cfg.VALIDATION.VALIDATION_PERIOD,
                                          model=self.model,
                                          data_loader=data_loader)
            hooks.insert(index=-1,
                         obj=loss_eval_hook)

        return hooks

 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.train_net:52
==compfigsep.panel_splitting.train_net:45
from compfigsep.utils.detectron_utils import LossEvalHook, add_validation_config


class Trainer(DefaultTrainer):
    """
    We use the "DefaultTrainer" which contains pre-defined default logic for
    standard training workflow.

    Here, the Trainer is able to perform validation.
    """

    @classmethod
    def build_evaluator(cls,
                        cfg: CfgNode, (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.label_recog_retinanet:237
==compfigsep.panel_segmentation.panel_seg_retinanet:397
        num_images: int = len(gt_classes)

        # shape(gt_classes) = (N, R)
        gt_classes_tensor: Tensor = torch.stack(gt_classes)

        # shape(anchors) = (R, 4)
        anchors_tensor: Tensor = type(anchors[0]).cat(anchors).tensor
        gt_anchor_deltas: List[Tensor] = [self.box2box_transform.get_deltas(anchors_tensor, k)
                                          for k in gt_boxes]
        # shape(gt_anchor_deltas) = (N, R, 4)
        gt_anchor_deltas_tensor: Tensor = torch.stack(gt_anchor_deltas)

        valid_mask: Tensor = gt_classes_tensor >= 0 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.bin.export_imageclef_figures_to_csv:60
==compfigsep.data.bin.export_iphotodraw_figures_to_csv:60
                        type=str)

    parser.add_argument('--output_csv',
                        help="The path of the csv file to which annotations have to be exported.",
                        default="data/imageCLEF/test/test.csv",
                        type=str)

    parser.add_argument('--individual_csv',
                        help="Also export the annotations to a single csv file.",
                        action='store_true')

    parser.add_argument('--individual_export_csv_directory', (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.train_net:38
==compfigsep.panel_splitting.train_net:33
from detectron2.checkpoint import DetectionCheckpointer # type: ignore
from detectron2.config import CfgNode, get_cfg # type: ignore
from detectron2.engine import (DefaultTrainer, # type: ignore
                               default_argument_parser, # type: ignore
                               default_setup, # type: ignore
                               launch, # type: ignore
                               HookBase) # type: ignore
from detectron2.evaluation import verify_results # type: ignore
from detectron2.data.build import build_detection_test_loader # type: ignore
from detectron2.data.dataset_mapper import DatasetMapper # type: ignore
 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.bin.export_iphotodraw_figures_to_csv:52
==compfigsep.data.bin.preview_panelseg_data_set:51
    parser.add_argument('--file_list_txt',
                        help="The path to the txt file listing the images.",
                        default="data/zou/eval.txt",
                        type=str)

    parser.add_argument('--image_directory_path',
                        help="The path to the directory where the images are stored.",
                        default=None,
                        type=str)
 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.train_net:36
==compfigsep.panel_segmentation.train_net:37
import detectron2.utils.comm as comm # type: ignore
from detectron2.utils.logger import setup_logger # type: ignore
from detectron2.checkpoint import DetectionCheckpointer # type: ignore
from detectron2.config import CfgNode, get_cfg # type: ignore
from detectron2.engine import (DefaultTrainer, # type: ignore
                               default_argument_parser, # type: ignore
                               default_setup, # type: ignore
                               launch, # type: ignore
                               HookBase) # type: ignore
from detectron2.evaluation import verify_results # type: ignore (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.label_recog_retinanet:398
==compfigsep.panel_segmentation.panel_seg_retinanet:601
        boxes_all: List[Tensor] = []
        scores_all: List[Tensor] = []
        class_idxs_all: List[Tensor] = []

        # Iterate over every feature level
        for box_cls_i, box_reg_i, anchors_i in zip(box_cls, box_delta, anchors):
            # (HxWxAxK,)
            box_cls_i = box_cls_i.flatten().sigmoid_()

            # Keep top k top scoring indices only. (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.utils.figure.label.label:251
==compfigsep.utils.figure.panel:236
        super().draw(image, color)


    def __str__(self) -> str:
        string = super().__str__()

        if self.detection_score is not None:
            string += f", detection_score: {self.detection_score}"
 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.label_recog_retinanet:410
==compfigsep.panel_segmentation.panel_seg_retinanet:613
            predicted_prob, topk_idxs = box_cls_i.sort(descending=True)
            predicted_prob = predicted_prob[:num_topk]
            topk_idxs = topk_idxs[:num_topk]

            # filter out the proposals with low confidence score
            keep_idxs = predicted_prob > self.score_threshold
            predicted_prob = predicted_prob[keep_idxs]
            topk_idxs = topk_idxs[keep_idxs]
 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.label_recog_retinanet:96
==compfigsep.panel_segmentation.panel_seg_retinanet:139
        self.focal_loss_alpha: float = cfg.MODEL.RETINANET.FOCAL_LOSS_ALPHA
        self.focal_loss_gamma: float = cfg.MODEL.RETINANET.FOCAL_LOSS_GAMMA
        self.smooth_l1_loss_beta: float = cfg.MODEL.RETINANET.SMOOTH_L1_LOSS_BETA
        # Inference parameters:
        self.score_threshold: float = cfg.MODEL.RETINANET.SCORE_THRESH_TEST
        self.topk_candidates: int = cfg.MODEL.RETINANET.TOPK_CANDIDATES_TEST
        self.nms_threshold: float = cfg.MODEL.RETINANET.NMS_THRESH_TEST
        self.max_detections_per_image: int = cfg.TEST.DETECTIONS_PER_IMAGE
        # Vis parameters (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.bin.export_imageclef_figures_to_csv:28
==compfigsep.data.bin.export_imageclef_figures_to_tfrecord:29
import sys
from argparse import ArgumentParser, Namespace

from typing import List

sys.path.append(".")

from compfigsep.data.figure_generators import ImageClefXmlFigureGenerator (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.bin.preview_imageclef_data_set:28
==compfigsep.data.bin.preview_json_data_set:28
import sys
import os
from argparse import ArgumentParser, Namespace

from typing import List

sys.path.append('.')
 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.figure_generators.global_csv_figure_generator:100
==compfigsep.data.figure_generators.image_clef_xml_figure_generator:120
            try:
                figure.load_image()
            except FileNotFoundError as exception:
                logging.error(exception)
                continue

            # Loop over the panels (object_items)
            subfigures = [] (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.panel_segmentation.train_net:39
==compfigsep.panel_splitting.train_net:33
from detectron2.checkpoint import DetectionCheckpointer # type: ignore
from detectron2.config import CfgNode, get_cfg # type: ignore
from detectron2.engine import (DefaultTrainer,
                               default_argument_parser,
                               default_setup,
                               launch,
                               HookBase) # type: ignore
from detectron2.evaluation import verify_results # type: ignore (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.evaluate:70
==compfigsep.panel_segmentation.evaluate:62
        stat_dict['overall_gt_count'] += 1

        if cls not in stat_dict['gt_count_by_class']:
            stat_dict['gt_count_by_class'][cls] = 1
        else:
            stat_dict['gt_count_by_class'][cls] += 1

 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.evaluator:73
==compfigsep.panel_splitting.evaluator:76
            boxes = instances.pred_boxes.tensor.numpy()
            scores = instances.scores.tolist()
            classes = instances.pred_classes.tolist()

            # Store predictions.
            predicted_panels = []
            for box, score, cls in zip(boxes, scores, classes):
                prediction = {} (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.label_recog_retinanet:251
==compfigsep.panel_segmentation.panel_seg_retinanet:411
        num_pos_anchors: int = pos_mask.sum().item()
        get_event_storage().put_scalar("num_pos_anchors",
                                       num_pos_anchors / num_images)
        self.loss_normalizer = self.loss_normalizer_momentum * self.loss_normalizer\
                                + (1 - self.loss_normalizer_momentum) * max(num_pos_anchors, 1)

        # classification and regression loss
        # no loss for the last (background) class --> [:, :-1] (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.data.bin.export_imageclef_figures_to_csv:101
==compfigsep.data.bin.export_iphotodraw_figures_to_csv:100
        output_csv_file=args.output_csv,
        individual_export=args.individual_csv,
        individual_export_csv_directory=args.individual_export_csv_directory)


if __name__ == '__main__':
    main() (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 3 files
==compfigsep.data.bin.export_iphotodraw_figures_to_csv:55
==compfigsep.data.bin.preview_panelseg_data_set:54
==compfigsep.data.figure_generators.iphotodraw_xml_figure_generator:55
                        type=str)

    parser.add_argument('--image_directory_path',
                        help="The path to the directory where the images are stored.",
                        default=None,
                        type=str)
 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 3 files
==compfigsep.data.figure_generators.global_csv_figure_generator:100
==compfigsep.data.figure_generators.image_clef_xml_figure_generator:120
==compfigsep.data.figure_generators.iphotodraw_xml_figure_generator:145
            try:
                figure.load_image()
            except FileNotFoundError as exception:
                logging.error(exception)
                continue

            # Loop over the panels (object_items) (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.panel_segmentation.evaluator:56
==compfigsep.panel_splitting.evaluator:55
                         evaluation_function=evaluate_detections,
                         export=export,
                         export_dir=export_dir)


    def process(self,
                inputs: List[dict], (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.panel_segmentation.train_net:249
==compfigsep.panel_splitting.train_net:173
        res = Trainer.test(cfg, model)
        if comm.is_main_process():
            verify_results(cfg, res)
        return res

    # Training
    trainer = Trainer(cfg) (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.label_recog_retinanet:75
==compfigsep.panel_segmentation.panel_seg_retinanet:85
    label_fpn: nn.Module = FPN(bottom_up=bottom_up,
                               in_features=label_in_features,
                               out_channels=label_out_channels,
                               norm=cfg.MODEL.FPN.NORM,
                               top_block=None,
                               fuse_type=cfg.MODEL.FPN.FUSE_TYPE)
 (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.panel_segmentation.train_net:269
==compfigsep.panel_splitting.train_net:189
    launch(main,
           parsed_args.num_gpus,
           num_machines=parsed_args.num_machines,
           machine_rank=parsed_args.machine_rank,
           dist_url=parsed_args.dist_url,
           args=(parsed_args,)) (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.label_recognition.label_recog_retinanet:568
==compfigsep.panel_segmentation.panel_seg_retinanet:819
        logits: List[Tensor] = []
        bbox_reg: List[Tensor] = []

        for feature in features:
            logits.append(self.cls_score(self.cls_subnet(feature)))
            bbox_reg.append(self.bbox_pred(self.bbox_subnet(feature))) (duplicate-code)
compfigsep/panel_splitting/evaluate.py:1:0: R0801: Similar lines in 2 files
==compfigsep.panel_segmentation.evaluate:106
==compfigsep.panel_splitting.evaluate:133
            'num_samples': 0,
            'overall_gt_count': 0,
            'overall_detected_count': 0,
            'detections': SortedKeyList(key=lambda u: -u[0]),
            'overall_correct_count': 0, (duplicate-code)

------------------------------------------------------------------
Your code has been rated at 8.91/10 (previous run: 8.91/10, +0.00)

